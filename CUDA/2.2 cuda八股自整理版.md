# CUDA 编程关键点整理

## 关键词

- 调度单位：warp
- 执行单位：thread
- Warp分歧：warp divergence
- 线程块：warp, shared memory, 线程块内线程同步
- Grid：执行相同kernel的线程块可在多个SM并行执行
- 索引和维度：threadIdx, blockIdx, blockDim, gridDim
- CUDA运行时库：cudaMalloc, cudaMemcpy, cudaFree, cudaErrorCheck, cudaKernelClock, cudaMemset, cudaEvent系列函数
- 内存事务和缓存行：Memory Coalescing, Cache Line
- 进阶知识点：内联PTX汇编，带宽，错误检查，线程和线程块资源限制，CUDA资源复用，获取GPU信息，CUDA主函数流程，dim3类型，cudaError_t，SIMD与SIMT区别，warp上下文与状态，内存层次结构，CUDA流

## 内容整理

### 调度和执行

- **调度单位（warp）**：在CUDA中，warp是一组同时执行的线程，数量通常为32，由warp scheduler进行调度。
- **执行单位（thread）**：每个线程独立执行分配给它的计算任务。

### Warp分歧（warp divergence）

- 分支时warp内线程走向不同执行路径，导致执行效率降低。CUDA运行时将按顺序检查所有分支，并且禁用那些没有走这条路径的线程。

### 线程块和Grid

- **线程块**：由warp组成，拥有shared memory，块内线程可以同步执行，且在同一个Stream Multiprocessor上执行。
- **Grid**：多个线程块组成，执行相同的kernel，可以在多个SM上并行执行。

### 索引和维度

- 使用`threadIdx`, `blockIdx`, `blockDim`, `gridDim`进行线程和块的索引和维度控制。

### CUDA运行时库

- 包括内存管理（`cudaMalloc`, `cudaFree`），数据传输（`cudaMemcpy`），错误检查，内核执行时间测量（`cudaEventCreate`, `cudaEventRecord`, `cudaEventSynchronize`, `cudaEventElapsedTime`, `cudaEventDestroy`）等。

### 内存事务和缓存行

- **内存事务（Memory Coalescing）**：当warp中的线程访问连续内存地址时，这些访问可以合并成一个更大的内存访问事务，提高访问效率。
- **缓存行（Cache Line）**：内存事务与缓存命中减少了从内存寻找数据的次数，直接减少访问次数或从快速访问的缓存中减少数据访问延迟。

### 进阶知识点

- **内联PTX（Parallel Thread Execution）汇编**：允许开发者直接使用底层GPU指令进行优化。
- **带宽（Bandwidth）**：单位时间内可以传输的数据量，关键于性能优化。
- **ErrorCheck**：CUDA API调用后的错误检查，确保程序稳定性。
- **线程和线程块的资源限制**：理解每个核函数的线程和线程块数量限制。
- **CUDA资源复用**：设备内存在核函数执行完毕后不会自动释放，可复用。
- **获取GPU信息**：了解GPU的硬件配置，优化计算策略。
- **CUDA主函数流程**：CUDA程序的标准流程，包括内存分配、内核执行和内存释放。
- **内存层次结构**：理解global memory, shared memory, register, constant memory的特性和使用场景。
- **CUDA流**：使用`cudaStream
- _t`, `cudaStreamCreate`, `cudaMemcpyAsync`, `cudaStreamSynchronize`, 和 `cudaStreamDestroy` 管理和优化异步执行流程。



### CUDA内存管理和同步

- **内存管理**：`cudaMalloc`, `cudaFree`, `cudaMemcpy`, `cudaMemset` 等函数用于在GPU上分配内存，复制数据以及初始化内存内容。
- **事件和时间测量**：使用 `cudaEventCreate`, `cudaEventRecord`, `cudaEventSynchronize`, `cudaEventElapsedTime`, 和 `cudaEventDestroy` 测量内核执行时间和事件同步，用于性能优化和分析。

### CUDA核函数执行配置

- **dim3类型**：用于指定核函数的网格（grid）和块（block）的三维结构。
- **启动配置**：核函数通过 `<<<Grid, Block>>>` 语法启动，其中 `Grid` 和 `Block` 定义了内核的执行配置。

### CUDA错误检查

- **cudaError_t**：CUDA API函数的返回类型，用于错误检查和处理。

### Warp上下文与状态

- **Active Warp**：已经分配了寄存器和共享内存资源的warp。
- **Selected Warp**：被warp调度器选中执行的warp。
- **Stalled Warp**：等待数据的warp，可能因为内存访问延迟等原因被阻塞。
- **Eligible Warp**：准备就绪的warp，等待执行资源。

### 性能优化

- **峰值浮点性能公式**：$PeakFLOPS = F_{clk} \times N_{SM} \times T_{ins} \times 2$，反映了GPU的理论最大计算能力。
- **内存事务优化**：通过Memory Coalescing和合理使用向量类型（如`float4`）优化内存访问模式。
- **SIMD与SIMT的对比**：理解SIMD和SIMT在处理分支时的不同策略，以及warp分歧对性能的影响。
- **GPU内存层次结构**：优化使用global memory, shared memory, registers, 和 constant memory来提高性能。
- **CUDA流**：并发执行计算和数据传输，提高GPU资源的利用率。

## 进阶知识点

- **内存对齐和访问模式**：
  - CUDA性能优化的一个关键方面是确保内存访问是对齐的，特别是对全局内存的访问。数据对齐可以减少内存访问所需的事务次数，从而提高效率。
  - 优化访问模式，例如使用连续访问模式代替随机访问，可以减少内存访问延迟，并提高内存带宽利用率。
- **深入理解并优化warp分歧**：
  - Warp分歧发生在同一warp内的线程需要执行不同的代码路径时。虽然每个线程理论上可以独立执行不同的分支，但在实践中，GPU会序列化不同的分支路径，导致性能下降。
  - 优化技巧包括重新组织代码以减少分支，或者通过算术运算代替条件分支，以减少分歧的影响。
- **高级CUDA内存技术**：
  - 纹理内存和表面内存为特定类型的数据访问提供了缓存机制。它们特别适合于图形渲染和图像处理应用，其中数据访问模式可能包括二维或三维空间的局部性。
  - 了解这些特殊内存类型的使用和优化可以帮助开发高效的CUDA应用程序。
- **动态并行(Dynamic Parallelism)**：
  - CUDA动态并行允许GPU内核动态地启动其他内核，这可以简化某些算法的实现并提高灵活性。
  - 动态并行的使用需要仔细管理内存和同步，以避免性能下降。
- **CUDA图(Graphs)**：
  - CUDA图是CUDA 10之后引入的一项特性，它允许开发者以图形的形式构建整个CUDA应用的执行流，包括内核执行、内存传输和同步操作。
  - 使用CUDA图可以减少CPU和GPU之间的同步开销，提高应用程序的整体性能。
- **混合精度计算**：
  - 利用不同的数据类型（如半精度浮点数）可以在保持足够精度的前提下提高计算速度和减少内存使用。
  - 混合精度计算在深度学习等领域尤为重要，因为它可以显著加速训练过程和推理过程。