# 1.cublas库

 cuBLAS, cuBLAS Xt, 和 cuBLAS Lt 是 NVIDIA CUDA 基础线性代数子程序库 (cuBLAS) 的不同组成部分，每个部分针对不同的使用场景和需求进行了优化。以下是每个API的简要解释和它们之间的主要区别：

### cuBLAS：`cublas_v2.h`,

- **描述**：cuBLAS 是 CUDA 的一个标准组件，提供了许多基础的线性代数函数，如向量和矩阵加法、乘法等，这些函数高度优化以利用 NVIDIA GPU 的并行处理能力。
- **用途**：适用于需要高性能线性代数运算的应用程序，比如深度学习、科学计算等。
- **特点**：提供了大量标准的BLAS操作，支持多种数据类型（包括单精度和双精度浮点数），是最通用的GPU加速线性代数运算库。

> 在4.0之后，新的cublas_v2.h替代了老的cublas库
>
> * 使用一个函数来初始化库上下文指针handle，并显式的传递给每个library function call，这使得用户能够更细粒度的控制Liberary setup,特别是multi-host以及multi-GPU的场景
> * 允许了$\alpha,\beta$在host与device上引用传递
> * 所有 cuBLAS 库函数调用都会返回错误状态 `cublasStatus_t`
> * 

### cuBLAS Xt

- **描述**：cuBLAS Xt 是 cuBLAS 的扩展接口，旨在提供跨多个GPU的自动分布式计算功能。
- **用途**：适合于需要在==多个GPU==上进行大规模线性代数计算的应用程序。它通过自动分配计算任务到多个GPU，可以显著提高大规模矩阵运算的性能。
- **特点**：允许用户更加轻松地在多GPU环境中利用cuBLAS进行计算，无需手动管理数据分布和收集。尤其适用于大矩阵的运算，其中单个GPU的内存可能不足以存储整个数据集。

### cuBLAS Lt

- **描述**：cuBLAS Lt 是 cuBLAS 库的另一个扩展，专注于提供更加灵活的矩阵乘法API，允许用户进行更细致的性能调优。
- **用途**：特别适合于深度学习中的混合精度计算和低精度计算，如使用半精度浮点数（FP16）和整数（INT8）进行矩阵乘法，以及需要手动优化计算性能的高级用户。
- **特点**：提供了丰富的配置选项，包括可调节的内存布局、计算精度和硬件资源使用。通过这些高级功能，用户可以针对特定的硬件和算法需求调优性能。

### 总结

- **cuBLAS** 提供了一组完整的标准BLAS运算，适合各种需要高性能线性代数运算的应用。
- **cuBLAS Xt** 扩展了 cuBLAS，使其能够利用多个GPU进行大规模线性代数运算，适用于大型计算任务。
- **cuBLAS Lt** 专注于提供灵活的矩阵乘法API和混合精度计算，允许进行详细的性能调优，特别适用于深度学习等需要高效计算的场景。





# 2. 数据布局



## 2.1 列主序

注意，cudaC不要求使用列主存，因为你直接决定如何访问其数据，但是封装好的cublas库实现时使用列主序，这样在矩阵乘法时能够获得更高效的内存hit。

>
> 列主存储（Column-major order）是一种在内存中组织二维数组的方法，其中先连续存储同一列的元素，再存储下一列的元素。这与行主存储（Row-major order）形成对比，后者先连续存储同一行的元素，再存储下一行的元素。
>
> ### 列主存储的例子
>
> 假设我们有一个3x2的矩阵A，其形式如下：
>
> ```
> A = | a11 a12 |
>     | a21 a22 |
>     | a31 a32 |
> ```
>
> 在列主存储中，这个矩阵在内存中的布局会是这样的：
>
> ```
> | a11 | a21 | a31 | a12 | a22 | a32 |
> ```
>
> 即首先存储第一列的所有元素（`a11, a21, a31`），然后是第二列的所有元素（`a12, a22, a32`）。

现在考虑几种情况，因为普通C++是行主存的，所以我们必须转换为列主存数据传给cublas。

数据可以分为两种情况：自己创建的矩阵以及已经存在的行主序矩阵，这两种处理方法一致。

==用一维数组存储：==

在C或C++中，你通常会使用一维数组来模拟列主序矩阵。考虑一个3x2的矩阵，你可以这样声明和初始化它：

```c++
const int rows = 3;
const int cols = 2;
float A[rows * cols] = {3, 3, 3, 2, 2, 2}; // 列主序
```

这里，矩阵`A`被视为列主序排列，第一列（3, 3, 3）先填充，然后是第二列（2, 2, 2）。如果你想按行和列访问这个矩阵中的元素，需要计算索引：

```c++
int index = column * rows + row;
```

考虑到在编程中你尝尝需要对不同的行主序，列主序二维矩阵访问数值，为了减少脑细胞损耗（Fortran的列主序1开始，C的行主序0开始，以及考虑cuda中通常是访问一个指针*，相当于操作一维数组），因此Nvidia给你了两个预处理宏来==快速访问列主序的二维矩阵指针==

```c++
//在fortran的语境下
#define IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))
//在普通c的语境下，也是一般使用的方法
#define IDX2C(i,j,ld) (((j)*(ld))+(i))
```

这里因为是列主序，所以ld指的是总行数（列中的元素数），考虑到Fortran从1开始数，因此需要-1。



## 2.2 基于1索引

cuBLAS库遵循Fortran的约定，使用基于1的索引，这是因为cuBLAS设计时主要考虑到与Fortran语言的兼容性。Fortran语言在数组索引上是从1开始的，而不是像C和C++那样从0开始。这个设计决策对于使用cuBLAS API时有一些特定的影响：

### 对使用cuBLAS API的影响

1. **API参数解释**：当你使用cuBLAS函数传递矩阵的维度或者向量的长度时，这些值是按照从1开始计数的。例如，如果你有一个大小为`n`的向量，在cuBLAS函数中你直接传递`n`作为参数，而不需要做任何调整。
2. **在C/C++中处理索引**：尽管cuBLAS使用基于1的索引，但在C或C++中，数组和指针仍然是基于0的索引。因此，当你在C或C++程序中计算需要传递给cuBLAS函数的索引或偏移量时，你可能需要进行一些转换，以确保数据的正确位置被访问。特别是在直接操作元素或者使用指针偏移时，需要记住这一点。
3. **混合使用cuBLAS和C/C++标准库**：在同一个程序中，当你需要使用标准C/C++库函数和cuBLAS函数共同操作数组或矩阵时，应该格外注意索引的差异。你可能需要在索引转换之间进行适当的调整，以确保所有操作都在正确的数据元素上执行。

### 示例

假设你想使用cuBLAS函数计算两个向量的点积。在C/C++中，向量的索引将从0开始，但在调用cuBLAS的点积函数时，你会按照向量的实际长度来传递参数，而不需要减1。

```c++
int n = 5; // 向量长度
float x[5] = {1, 2, 3, 4, 5};
float y[5] = {5, 4, 3, 2, 1};
float result;
// 假设handle是已初始化的cuBLAS上下文句柄
cublasSdot(handle, n, x, 1, y, 1, &result);
```

在这个例子中，尽管`x`和`y`是基于0的索引数组，`n`直接传递给`cublasSdot`函数作为向量的长度，而不需要对其进行任何调整，因为cuBLAS期待的是向量的实际长度，这与索引的基础（从1开始或从0开始）无关。







## ld:Leading Dimension

`ld`在矩阵运算和线性代数库中通常代表“领先维度”（Leading Dimension）。在二维数组或矩阵的上下文中，领先维度是存储矩阵时内存中连续元素的数量，这通常对应于矩阵的行数或列数，具体取决于矩阵是如何在内存中布局的（行主序还是列主序）。

### 在列主序存储中

对于列主序存储（如Fortran和某些数学库所采用的），`ld`指的是矩阵的行数。当你在内存中按列存储矩阵时，每一列的元素是连续存储的。在这种情况下，`ld`告诉你每一列有多少元素，或者说，在移动到下一列的第一个元素之前，你需要跳过多少个元素。这对于正确地索引矩阵元素至关重要。

### 在行主序存储中

对于行主序存储（如C/C++所采用的），虽然`ld`的概念不常直接使用，但如果将其应用，它将指的是矩阵的列数。在内存中按行存储矩阵时，每一行的元素是连续存储的，而`ld`则会告诉你每一行有多少元素，或者说，在移动到下一行的第一个元素之前，你需要跳过多少个元素。

### 为什么领先维度很重要

在进行矩阵运算或调用基于矩阵的库函数时（如BLAS或cuBLAS），正确指定领先维度是非常重要的，因为它影响到库如何解释内存中矩阵的布局。如果`ld`指定不正确，函数可能会错误地解释矩阵数据，导致错误的计算结果。

### 示例

假设有一个3x4的矩阵A，按列主序存储在内存中：

```c++
A = | a11 a12 a13 a14 |
    | a21 a22 a23 a24 |
    | a31 a32 a33 a34 |
```

在这个例子中，`ld`是3，因为矩阵的行数是3，且矩阵是按列存储的。即便实际的列数是4，`ld`仍然是3，因为它表示的是内存中连续存储的元素数量（即列的长度），这在列主序存储的上下文中是行的数量。



# 3. 一个简单的例子

```c++

```

#### cudaMemcpy & cublasSetMatrix

`cublasSetMatrix`函数是cuBLAS库中用于将数据从主机（CPU）内存复制到设备（GPU）内存的一个函数。这个函数特别适用于处理二维数组（即矩阵），并且它自动处理好了与列主序存储相关的内存布局问题。其功能和`cudaMemcpy`相似，但`cublasSetMatrix`特别设计用于二维数据结构，并且考虑到了矩阵的行和列维度。

函数原型如下：

```c
cublasStatus_t cublasSetMatrix(
    int rows, 
    int cols, 
    int elemSize,
    const void *A, 
    int lda, 
    void *B, 
    int ldb
);
```

- **rows**：要复制的矩阵的行数。
- **cols**：要复制的矩阵的列数。
- **elemSize**：矩阵中每个元素的大小（字节），通常使用`sizeof(datatype)`来指定，比如`sizeof(float)`。
- **A**：源矩阵在主机内存中的地址。
- **lda**：源矩阵`A`的领先维度（leading dimension），在列主序中，它是矩阵的行数。
- **B**：目标矩阵在设备内存中的地址。
- **ldb**：目标矩阵`B`的领先维度，同样，在列主序中，它是矩阵的行数。

当涉及到将矩阵或多维数组数据从主机内存传输到GPU设备内存（或反向传输）时，cuBLAS库中的用户通常会使用专门的cuBLAS API函数（如`cublasSetMatrix`和`cublasGetMatrix`）而不是直接使用`cudaMemcpy`。这样做有几个原因：

##### 1. **为矩阵数据传输优化**

- **专门的API**：`cublasSetMatrix`和`cublasGetMatrix`函数专为矩阵数据设计，能够自动处理与列主序存储相关的内存布局问题，这是在数值计算和线性代数运算中非常常见的数据布局方式。这些函数了解矩阵的行和列维度，从而能够更有效地处理数据的复制操作。

##### 2. **简化代码**

- **易于使用**：使用`cublasSetMatrix`和`cublasGetMatrix`可以使代码更加简洁，因为你只需要指定矩阵的维度和领先维度，而不需要手动计算复制整个矩阵所需的总字节数。这减少了出错的可能性，并提高了代码的可读性。

##### 3. **保持一致性**

- **与cuBLAS库的兼容性**：使用cuBLAS库处理的程序通常会遵循Fortran的列主序存储约定。`cublasSetMatrix`和`cublasGetMatrix`天生支持这种数据布局，确保数据在传输过程中保持正确的格式，从而无缝与cuBLAS中的其他函数协同工作。

##### 4. **性能考虑**

- 尽管`cudaMemcpy`在功能上足够通用，能够处理任意形式的内存复制需求，但`cublasSetMatrix`和`cublasGetMatrix`可能针对矩阵数据传输进行了特定的优化，特别是在与GPU内存对齐和传输效率方面。









#### `cublasGetMatrix`

```
stat = cublasGetMatrix(M, N, sizeof(*a), devPtrA, M, a, M);
```

这行代码使用`cublasGetMatrix`将修改后的矩阵数据从GPU内存（`devPtrA`）复制回主机内存（`a`）。这里是参数的解释：

- `M`和`N`：矩阵的行数和列数。
- `sizeof(*a)`：每个矩阵元素的大小，确保正确地分配和复制内存。
- `devPtrA`：源地址，即GPU内存中矩阵的地址。
- `M`：源矩阵的领先维度，即每列的跨度。
- `a`：目标地址，即主机内存中矩阵的地址。
- `M`：目标矩阵的领先维度，同样是每列的跨度。

这个函数调用确保了修改后的矩阵数据被正确地从GPU传回到主机内存，以便进一步处理或验证。

#### `cublasSscal`

`cublasSscal`的原型如下：

```c
cublasStatus_t cublasSscal(
    cublasHandle_t handle, 
    int n, 
    const float *alpha, 
    float *x, 
    int incx
);
```

这个函数使用alpha scales输入x，然后将答案覆写

即为对(以fortran的形式来看)

对于$i = 1,...,n$与$j=1+(i-1)*incx$

执行$x[j] = \alpha \times x[j]$

也就是说，给定输入数组x，看作一个一维数组，

从1开始，对每跨incx步的元素做scale，因此incx在列主序中一般为行数



简单来说，就是给定vector x，给定其长度n，给定scale $\alpha$

从1开始按跨度$incx$乘上$\alpha$



##### 参数解释

- `handle`：cuBLAS库的上下文句柄，用于管理库函数的状态和资源。
- `n`：要处理的向量`x`的元素数量。
- `alpha`：指向标量`alpha`的指针，该标量将用于乘以向量`x`的每个元素。
- `x`：要处理的向量x的头指针
- `incx`：向量`x`的存储间隔，表示在遍历`x`的元素时应该在每次迭代中跳过的元素数量。通常，这个值被设置为1，表示`x`的元素是连续存储的。

##### 返回值

`cublasSscal`返回一个类型为`cublasStatus_t`的值，它表示函数调用的状态。如果函数成功执行，它将返回`CUBLAS_STATUS_SUCCESS`。如果有错误发生，它将返回一个不同的状态码，如`CUBLAS_STATUS_INVALID_VALUE`或`CUBLAS_STATUS_EXECUTION_FAILED`等，这取决于错误的类型。



