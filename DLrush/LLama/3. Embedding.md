## 1. embedding简介

在自然语言处理（NLP）中，将文本转换为计算机可理解的数值形式是基础且关键的步骤。随着时间的推移，从最初的标签化（Label Encoding）到独热编码（One-hot Encoding），再到现今广泛使用的嵌入（Embedding）技术，文本表示方法经历了显著的演变。这些技术各有优劣，但目标一致：有效捕捉语言的复杂性和丰富的语义信息。

* 标签化(Label Encoding)
  * 直接将每个词映射到一个唯一的整数。
  * 特点：
    * 简单直接。
    * 无法表示词之间的语义关系。
    * 假设词之间存在线性关系，这在大多数NLP任务中不成立。
* 独热编码(one-hot Encoding)
  * 为每个词生成一个向量，向量的长度等于词汇表的大小，其中表示当前词的位置为1，其余为0。
  * 特点：
    * 易于理解和实现。
    * 明确区分每个词。
    * 维度过高（与词汇表大小相等）。
    * 稀疏表示浪费存储空间和计算资源。
    * 无法捕捉词之间的语义关系。
* 词嵌入(Word2Vec)
  * 通过训练将每个词映射到一个低维的、稠密的向量空间中，向量中的距离和方向能反映词之间的语义关系。
  * 特点：
    * 降低维度，提高效率。
    * 稠密表示更有效地使用存储空间。
    * 能捕捉词之间的复杂语义关系，包括相似性和上下文关系。
    * 需要大量数据和计算资源进行训练。
    * 模型的选择和训练方式对最终效果有重要影响。



常用的Embedding方法有：

1. Word2Vec

   - **Skip-gram**：根据目标词预测上下文。

   - **CBOW（Continuous Bag of Words）**：根据上下文预测目标词。

   - 通过优化词与其上下文的关系，生成嵌入向量。

2. GloVe（Global Vectors for Word Representation）

   - 在全局词-词共现矩阵上训练，结合了矩阵分解和局部上下文窗口的优点。

   - 捕捉到更深层次的统计信息，反映了词之间的共现关系。

3. FastText

   - 类似于Word2Vec，但考虑了词内部的字符n-gram，能够处理生僻词和新词。

   - 对于语言中的形态变化和词根变化表现更好。

4. Transformer-based Embeddings

   - 如BERT、GPT系列，在大量文本上预训练，捕捉深层次的语言特征和上下文信息。

   - 生成的嵌入向量能够根据上下文动态调整，适用于复杂的NLP任务。



从推理的角度看

假设我们已经有了一个词汇表（vocabulary），并且针对这个词汇表，我们已经训练好了一个嵌入层（embedding layer）。在自然语言处理（NLP）任务的推理（inference）阶段，嵌入层的作用可以通过以下步骤来举例说明：

1. 输入转换

   - **输入**：假设输入文本是 "I love dogs"，并且每个词都已经在词汇表中有了相应的索引。例如，索引可能是 `"I"->0`, `"love"->1`, `"dogs"->2`。

   - **处理**：在推理时，首先将输入文本转换为词汇表索引的序列。对于这个例子，转换后的输入可能是 `[0, 1, 2]`。

2. 嵌入查找

   - **动作**：嵌入层根据输入序列中的索引，在预训练好的嵌入矩阵中查找每个词的向量表示。如果我们的嵌入向量维度是 `d`，那么每个词都对应着一个 `d` 维的向量。

   - 结果：对于上述输入 `[0, 1, 2]`，假设`d=4`，嵌入层可能会返回如下的向量序列：
     - `"I"` -> `[0.5, 0.1, -0.4, 0.3]`
     - `"love"` -> `[-0.2, 0.9, 0.3, 0.2]`
     - `"dogs"` -> `[0.4, -0.1, -0.5, 0.8]`

   - 这些向量捕捉了每个词的语义信息，并且是相对密集的表示。

3. 语义信息的携带
   - **重要性**：这些嵌入向量携带了词汇的语义信息，包括它们与其他词汇的关系以及在文本中的上下文意义。这是因为在嵌入向量的训练过程中，模型尝试使得语义上相似或相关的词汇在向量空间中距离相近。

4. 后续处理

   - **应用**：嵌入向量序列接下来会被送入模型的后续层（例如，循环神经网络（RNN）、长短期记忆网络（LSTM）、Transformer等），这些层会进一步处理嵌入向量以完成特定的NLP任务，如情感分析、文本分类、机器翻译等。

   - **优势**：与直接使用词索引或稀疏表示相比，这种基于嵌入向量的表示能够提供更丰富的输入信息给模型，从而提高模型在各种NLP任务上的表现。















## 2. Embedding的流程看起来应该是什么样


让我们通过一个具体的例子来解释如何从`input_ids`通过参考词汇表(`vocabulary`)得到嵌入向量(`output`)的过程。

### 词汇表和嵌入表

假设我们有一个非常小的词汇表和对应的嵌入表，为了简化，我们假设嵌入向量的维度(`hidden_size`)是2。

- **词汇表** (`vocabulary`):
  - "apple": 0
  - "banana": 1
  - "cherry": 2
- **嵌入表** (`embed_table`):
  - "apple" 对应的嵌入向量: [0.1, 0.2]
  - "banana" 对应的嵌入向量: [0.3, 0.4]
  - "cherry" 对应的嵌入向量: [0.5, 0.6]

这个嵌入表可以表示为一个2D数组，如下所示：

```c++
[[0.1, 0.2],  // apple
 [0.3, 0.4],  // banana
 [0.5, 0.6]]  // cherry
```

### 输入ID

接下来，我们有一个包含词汇ID的`input_ids`数组，它表示一个特定的词序列。假设我们的输入序列是：

- **输入序列** (`input_ids`): ["banana", "cherry", "apple"]
- 对应的索引表示为: [1, 2, 0]

### 输出

我们的目标是为这个序列中的每个词汇ID查找对应的嵌入向量，并将这些嵌入向量存储在`output`数组中。因此，对于这个例子，`output`将会是：

```c++
[0.3, 0.4,  // banana
 0.5, 0.6,  // cherry
 0.1, 0.2]  // apple
```

### 核函数操作

在GPU上，每个线程将根据它的`index`来计算它应该处理的数据点。对于我们的例子，设`hidden_size`为2，我们有3个词，所以`max_context_token_num * hidden_size`等于6。假设我们有足够的线程来处理这些数据点，每个线程的操作如下：

- 线程0处理"banana"的第一个维度：`input_ids[0 / 2]`得到`input_ids[0]`，即1（"banana"的索引）。然后，它查找嵌入[0.3, 0.4]中的第`0 % 2`个元素，即0.3，并将其放入`output[0]`。
- 线程1处理"banana"的第二个维度：`input_ids[1 / 2]`得到`input_ids[0]`，即1。它查找嵌入[0.3, 0.4]中的第`1 % 2`个元素，即0.4，并将其放入`output[1]`。
- 以此类推，直到线程5处理"apple"的第二个维度。

这个过程确保了每个输入词的嵌入向量按顺序被复制到输出数组中。





## Additional: 编程补充知识

### 1. enum

#### enum (传统枚举)

`enum`是C和早期C++中引入的枚举类型，它用于定义一个常量组，每个成员都有一个整数值。默认情况下，第一个成员的值为0，每个后续成员的值依次增加1。你也可以为枚举的成员指定特定的值。

**特点**：

- `enum`成员的作用域不受限制，这意味着所有枚举值都在包含它们的作用域内直接可见。
- `enum`类型的变量实际上是整型，因此可以与整数进行隐式转换，这可能导致类型安全问题。

**示例**：

```c++
enum Color { RED, GREEN, BLUE };
Color color = RED;
int colorValue = color; // 隐式转换为整数
```

#### enum class (强类型枚举)

`enum class`是在C++11中引入的，用于解决传统`enum`的一些问题，特别是关于作用域和类型安全的问题。

**特点**：

- `enum class`成员的作用域被限制在枚举类内部，避免了命名冲突。
- `enum class`不允许隐式转换为整数，提高了类型安全。如果需要获取枚举值的整数表示，必须进行显式转换。
- 默认情况下，`enum class`的底层类型是`int`，但你可以指定使用其他整数类型作为底层类型。

**示例**：

```c++
enum class Color { RED, GREEN, BLUE };
Color color = Color::RED; // 必须使用作用域解析运算符(::)
int colorValue = static_cast<int>(color); // 需要显式转换为整数
```









### 2.`half`

在C++标准中，`half`类型并不是内置的。然而，一些第三方库、特定的编译器扩展或者硬件加速API（如CUDA）提供了对半精度浮点数的支持。例如，在CUDA中，`half`类型用于表示在GPU上进行计算时可以使用的半精度浮点数，以提升性能和减少内存占用。使用`half`时通常需要包含相应的头文件或者使用特定的库来支持半精度的运算和处理。













### 3.`CHECK`宏

考虑到CUDA部分的报错十分的简洁，几乎不可读，因此设计CHECK宏来获取详细的信息

```c++
#define CHECK(call)                                   \
do                                                    \
{                                                     \
    const cudaError_t error_code = call;              \
    if (error_code != cudaSuccess)                    \
    {                                                 \
        printf("CUDA Error:\n");                      \
        printf("    File:       %s\n", __FILE__);     \
        printf("    Line:       %d\n", __LINE__);     \
        printf("    Error code: %d\n", error_code);   \
        printf("    Error text: %s\n",                \
            cudaGetErrorString(error_code));          \
        exit(1);                                      \
    }                                                 \
} while (0)
```

* `/`用于换行
* **宏定义**：使用`#define CHECK(call)`定义了一个预处理宏，`call`是宏的参数，代表CUDA API调用。
* **do-while循环**：使用`do { ... } while (0)`是一种常见的技巧，确保宏的使用就像一个语句一样，即使在没有花括号的情况下也能正常工作。这种结构使得宏在任何地方使用时都需要以分号结束，从而避免潜在的编译问题。
* **错误检查**：通过`call`执行CUDA API调用，并将返回的错误码存储在局部变量`error_code`中。然后，检查`error_code`是否等于`cudaSuccess`。如果不等于，说明调用失败。
* **错误处理**：如果检测到错误，使用`printf`函数打印出错误信息，包括发生错误的文件名（`__FILE__`）、行号（`__LINE__`）、错误码（`error_code`）以及通过`cudaGetErrorString(error_code)`获取的错误描述文本。这有助于开发者快速定位问题。
* **终止程序**：最后，使用`exit(1)`终止程序。`exit(1)`表示因为发生错误而终止，非零的退出码通常表示程序异常结束。

使用这个宏可以使CUDA程序的错误处理更加简洁和一致。你只需要在每个CUDA API调用后面使用`CHECK()`宏，如`CHECK(cudaMalloc((void**)&devPtr, size));`，这样一旦调用失败就会自动打印出有关错误的详细信息并终止程序。这是一种有效的调试和错误检查手段。









### 4.利用Assert进行防御性检查（LLM_CHECK）

```c++
inline void llmAssert(bool result, const char* const file, int const line, std::string const& info = "")
{
    if (!result) {
        throwRuntimeError(file, line, info);
    }
}

#define LLM_CHECK(val) llmAssert(val, __FILE__, __LINE__)
#define LLM_CHECK_WITH_INFO(val, info)                                                                              \
    do {                                                                                                               \
        bool is_valid_val = (val);                                                                                     \
        if (!is_valid_val) {                                                                                           \
            llmAssert(is_valid_val, __FILE__, __LINE__, (info));                                                    \
        }                                                                                                              \
    } while (0)

```

* llmAssert检查传递的布尔表达式result是否为true，如果为false则抛出一个error
  * `result`：要检查的布尔表达式。
  * `file`：传递给`throwRuntimeError`函数的文件名，通常使用宏`__FILE__`来获取当前代码文件的名称。
  * `line`：传递给`throwRuntimeError`函数的行号，通常使用宏`__LINE__`来获取当前代码的行号。
  * `info`：一个可选的字符串参数，提供额外的错误信息，其默认值为空字符串。
* LLM_CHECK:只需要传递一个表达式`val`，如果`val`为`false`，则使用当前文件名和行号调用`llmAssert`函数。
* LLM_CHECK_WITH_INFO: 与`LLM_CHECK`宏类似，但它允许传递一个额外的信息字符串`info`，提供关于失败条件的更多上下文。这在需要对错误进行更详细说明时非常有用。
  * 首先评估表达式`val`，将结果存储在局部变量`is_valid_val`中。如果`is_valid_val`为`false`，则调用`llmAssert`函数，并传入文件名、行号和额外的错误信息`info`。





### 5. Tensor类

```c++
```











### 6.  在class的member function中的static与constexpr

#### 6.1 类中的static

在C++类中，成员变量可以被声明为`static const`。这意味着该变量是与类相关联的，而不是与类的任何特定实例相关联。`const`指定该变量的值不能被修改（即，它是一个常量）。==`static const`成员变量对所有实例是共享的，并且它们必须在类外部被定义和初始化（除了整型或枚举类型的常量，它们可以在类内部被直接初始化）。==

**示例：**

```c++
class MyClass {
public:
    static const int myConst = 42; // 直接初始化是允许的，因为它是整型常量

    // 对于非整型的static const成员，比如下面的string，你需要在类外初始化它：
    static const std::string myStringConst;
};

// 类外初始化
const std::string MyClass::myStringConst = "Hello, World!";
```

**特性和用法：**

1. **共享**：`static const`成员是类级别的，不属于任何特定的实例。这意味着它们的值在所有实例之间是共享的。
2. **内存效率**：由于`static const`成员是共享的，所以无论创建了多少个类的实例，都只有一个`static const`成员的副本。
3. **访问控制**：`static const`成员可以是私有的，这样它们就只能通过类的静态成员函数或友元函数访问。如果它们是公共的，可以直接通过类名访问，而不需要任何类的实例。
4. **常量表达式**：`static const`成员常用于定义类级别的常量值，这些值在编译时已知，可以用于数组大小声明等场合。
5. **类型安全**：与使用宏定义常量相比，`static const`成员提供了类型安全，因为它们是强类型的。

 **注意事项：**

- 对于非整数类型的静态常量成员（例如`std::string`），你必须在类定义外部进行初始化。
- 从C++11开始，你也可以使用`constexpr`关键字来声明和定义类内部的静态常量成员，`constexpr`提供了更广泛的编译时常量表达式支持。

使用`static const`成员变量是C++中管理类级常量的一种有效方式，使得代码更加模块化和易于维护。



在C++中，只有整型或枚举类型的`static const`成员变量可以在类定义内部直接初始化的原因主要与C++编译时常量的处理方式有关。==整型和枚举类型的常量可以在编译时完全确定其值，这使得编译器可以在不需要单独存储空间的情况下，将这些常量的值直接替换到它们被使用的地方。==这种行为符合C++对于编译时常量的优化原则，即避免不必要的运行时开销。



#### 6.2 使用constexpr拓展编译时确定的值

```c++
class{
    void func(){
	    constexpr static const double a = 0;
    }
};

```



`constexpr`是C++11引入的一个关键字，用于声明可以在编译时求值的常量表达式。与传统的`const`不同，`constexpr`表达的是编译时的常量性，它允许更广泛的编译时计算，包括对函数的应用。使用`constexpr`可以显著提高程序的性能，因为它减少了运行时的计算需求。`constexpr`可用于变量、函数、构造函数以及用户定义的字面类型。

##### `constexpr` 可以作用于的类型和场景包括：

1. **基本数据类型**：整数、字符、浮点数等基本类型的变量可以被声明为`constexpr`，表示它们是编译时常量。

   ```c++
   constexpr int max_size = 100;
   constexpr double pi = 3.14159;
   ```

2. **指针和引用**：指向常量的指针和引用可以被声明为`constexpr`。这==适用于指向全局或静态存储持续时间的对象。==

   ```c++
   constexpr const int* ptr = &max_size;
   constexpr const int& ref = max_size;
   ```

3. **自定义字面类型（Literal Types）**：用户定义的类型，如果它们的构造函数和析构函数满足`constexpr`的要求（即，它们不执行任何非常量表达式的操作），则这些类型的对象也可以被声明为`constexpr`。

   ```c++
   class Point {
   public:
       constexpr Point(double x, double y) : x_(x), y_(y) {}
       constexpr double x() const { return x_; }
       constexpr double y() const { return y_; }
   
   private:
       double x_, y_;
   };
   
   constexpr Point p(1.0, 2.0);
   ```

4. **函数和构造函数**：如果一个函数或构造函数的返回值或效果可以在编译时确定，那么它可以被声明为`constexpr`。这样的函数只能包含常量表达式、条件语句、循环（在C++14中放宽了条件）和对其他`constexpr`函数的调用。

   ```c++
   constexpr int square(int x) {
       return x * x;
   }
   ```

   使用`constexpr`函数可以在编译时计算出表达式的值，如`constexpr int val = square(5);`。

##### 注意事项：

* C++14和C++17进一步放宽了`constexpr`函数的限制，允许它们包含更多种类的语句，如局部变量声明、循环和分支等。

* `constexpr`表达式的结果必须在编译时可知，因此它们不能依赖于运行时的任何动态信息。

* 使用`constexpr`时，必须确保==所有相关的操作都满足`constexpr`的要求==。

  * ```c++
    //编译时常量例子
    constexpr int getCompileTimeValue() {
        return 5 * 2; // 完全在编译时就可以计算出来
    }
    
    int main() {
        constexpr int compileTimeValue = getCompileTimeValue(); // 编译时常量
        int arr[compileTimeValue]; // 使用编译时常量作为数组大小
        // ...
    }
    
    ```

  * ```c++
    //依赖运行时信息-用户输入
    #include <iostream>
    
    constexpr int getRuntimeValue(int input) {
        return input * 2; // 结果取决于运行时传入的参数
    }
    
    int main() {
        int runtimeInput;
        std::cin >> runtimeInput; // 从用户输入获取值
        constexpr int runtimeValue = getRuntimeValue(runtimeInput); // 编译错误：input 在运行时才确定
        // ...
    }
    
    ```

* **运行时动态信息就是非常量表达式**：

  * **含有非常量操作**：如动态内存分配（`new`、`delete`）、静态或全局变量的修改、调用非`constexpr`函数等。

  * (使用了)非constexpr函数：例如递归会调用自己，需要将自己设置为constexpr

    * ```c++
      int factorial(int n) {
          if (n <= 1) return 1;
          else return n * factorial(n - 1);
      }
      
      
      constexpr int factorial(int n) {
          return n <= 1 ? 1 : n * factorial(n - 1);
      }
      
      ```

  * 运行时资源：文件I/O，非constexpr库函数

  * **运行时数据依赖**：如果表达式依赖于运行时才能确定的数据，比如用户输入、文件内容、或者网络数据等，那么这个表达式就是非常量表达式

























### 7. `initializer_list`


在C++11及其后续版本中，`std::initializer_list`是一种标准库类型，用于表示一个值的列表。它允许函数接受一个花括号 `{}` 包围的值列表作为参数，这种语法通常用于初始化数组、容器，或者用于创建对象时给构造函数传递多个参数。`std::initializer_list`在`<initializer_list>`头文件中定义。

#### 主要特性

- **统一初始化**：`std::initializer_list`允许你用同样的初始化列表语法初始化各种数据类型，包括自定义类型、容器和数组。
- **自动类型推导**：在使用初始化列表时，编译器能够根据列表中的值自动推导出`std::initializer_list`的元素类型。
- **只读访问**：通过`std::initializer_list`提供的接口，你只能读取列表中的元素，不能修改它们。

#### 使用示例

##### 1. 初始化标准库容器

```
cppCopy code#include <vector>
#include <initializer_list>

std::vector<int> vec = {1, 2, 3, 4, 5}; // 使用初始化列表初始化vector
```

##### 2. 函数接受初始化列表参数

```
cppCopy code#include <iostream>
#include <initializer_list>

void print(std::initializer_list<int> ilist) {
    for (auto elem : ilist) {
        std::cout << elem << ' ';
    }
    std::cout << '\n';
}

int main() {
    print({1, 2, 3, 4, 5}); // 调用print函数，传递初始化列表
}
```

##### 3. 自定义类型支持初始化列表

```
cppCopy code#include <iostream>
#include <initializer_list>

class CustomType {
public:
    CustomType(std::initializer_list<int> ilist) {
        for (auto elem : ilist) {
            std::cout << elem << ' ';
        }
        std::cout << '\n';
    }
};

int main() {
    CustomType obj = {1, 2, 3, 4, 5}; // 使用初始化列表创建CustomType对象
}
```

#### 注意事项

- 初始化列表中的元素是只读的，`std::initializer_list`对象并不拥有其元素。实际的元素是在编译时创建的临时数组中。
- `std::initializer_list`通常用于构造函数和函数参数，提供了一种便捷和统一的方式来初始化数据。
- 由于`std::initializer_list`使用花括号初始化语法，它可以与“统一初始化”（uniform initialization）和“列表初始化”（list initialization）概念一起使用，从而减少了初始化数据时的歧义和错误。

`std::initializer_list`的引入使得C++的初始化语法更加一致和强大，极大地增强了语言的表达能力和便利性。



在TensorMap中，对应的

```c++
class TensorMap {
public:
    // 假设TensorMap有一个添加元素的成员函数
    void add(const std::string& key, Tensor* value) {
        // 添加键值对到映射中的逻辑
    }

    // 构造函数使用std::initializer_list
    TensorMap(std::initializer_list<std::pair<std::string, Tensor*>> tensor_map) {
        for (const auto& kv : tensor_map) {
            add(kv.first, kv.second); // 添加每个键值对
        }
    }
};
// 创建TensorMap对象，传递一个初始化列表
TensorMap tensorMap({
    {"key1", tensor1},
    {"key2", tensor2},
    // 可以继续添加更多的键值对
});

```







### 8. random_device()

`std::random_device`是C++11标准库中提供的一个非确定性随机数生成器（non-deterministic random number generator），用于生成高质量的随机数。它通常用于作为种子（seed）来初始化其他类型的随机数生成器，如`std::mt19937`（一个梅森旋转算法的实现）。

#### 使用`std::random_device`

```c++
#include <random>
#include <iostream>

int main() {
    std::random_device rd; // 创建一个随机设备
    std::cout << "Random Number: " << rd() << std::endl; // 生成一个随机数并打印

    // 使用random_device作为种子来初始化一个随机数引擎
    std::mt19937 gen(rd());
    std::uniform_int_distribution<> dis(1, 6); // 定义一个范围在1到6之间的均匀分布
    std::cout << "Dice Roll: " << dis(gen) << std::endl; // 模拟掷骰子

    return 0;
}
```

#### 特性和用途

- `std::random_device`旨在提供尽可能不可预测的随机数。它通常实现为一个硬件随机数生成器，但如果系统不支持硬件生成，它可能回退到一个伪随机数生成器。
- 因为`std::random_device`可能使用系统的硬件特性，所以它生成的随机数的质量通常比标准库中的伪随机数生成器更高，特别适合作为种子使用。
- 在使用`std::random_device`初始化伪随机数生成器时，可以提高伪随机序列的不可预测性，这对于需要高随机性的应用（如密码学应用）尤其重要。

#### 注意事项

- `std::random_device`的使用可能比其他随机数生成器更耗时，因此它不推荐用于大量高速随机数的生成。相反，它更适合作为初始化其他随机数生成器的种子。
- 在某些实现中，如果`std::random_device`不支持硬件生成随机数，它可能每次都产生相同的值。因此，在依赖它提供不同种子的场景下，建议检查其行为或查阅相关文档。

`std::random_device`是C++提供的一个强大工具，用于生成高质量的随机数，特别适用于需要高随机性的场景。





## 3.embedding实现

将词汇索引映射到它们的嵌入向量表示

### 2.1 头文件

这里我们的InputEmbedding需要传入三个数据，分别是Input,Vocabulary

```c++
//input_embedding.h

# include<cuda_runtime.h>
# include<cuda.h>
# include<cuda_fp16.h>
# include "src/utils/tensor.h"
# include "src/weight/llama/embedding_weights.h"


template<typename T>
void launchInputEmbedding(TensorWrapper<int>* input_ids,
                         TensorWrapper<T>* output,
                         EmbeddingWeight<T>* embed_table);
```



### 2.2 输入embedding层

* embeddingFunctor:CUDA核函数模板，用于执行嵌入查找操作。

  * `input_ids`：整型指针，指向存储词汇索引的数组。
  * `output`：模板类型`T`的指针，指向输出的嵌入向量数组。
  * `embed_table`：模板类型`T`的指针，指向嵌入权重表。
  * `max_context_token_num`：表示输入`input_ids`中的最大令牌（token）数。
  * `hidden_size`：每个嵌入向量的维度。

  核函数的执行逻辑是对于`output`数组中的每个元素，根据`input_ids`中的索引从`embed_table`查找对应的嵌入向量并赋值给`output`。

  ```c++
  template<typename T>
  __global__ void embeddingFunctor(const int* input_ids,
                 T* output, 
                 const T* embed_table,
                 const int max_context_token_num,
                 const int hidden_size)
  {
      int index = blockIdx.x * blockDim.x + threadIdx.x;
      
      while (index < max_context_token_num * hidden_size) {
          int id = input_ids[index / hidden_size];
          output[index] = embed_table[id * hidden_size + index % hidden_size];
          index += blockDim.x * gridDim.x;
      }
  }
  ```

  

* launchInputEmbedding():是上面那个核函数的launcher

  * `input_ids`：`TensorWrapper<int>`类型，封装了包含词汇索引的张量。
  * `output`：`TensorWrapper<T>`类型，封装了输出嵌入向量的张量。
  * `embed_table`：`EmbeddingWeight<T>`类型，封装了嵌入权重表的张量。

  
