## 1. 简介

cuBLAS是NVIDIA CUDA基础线性代数子程序库（CUDA Basic Linear Algebra Subprograms library）的缩写。它是一套在NVIDIA图形处理单元（GPU）上执行的高性能数学计算函数库，专门用于线性代数计算。作为CUDA工具套件的一部分，cuBLAS库提供了许多用于浮点数和复数的基本线性代数函数，这些函数经过优化，可以充分利用NVIDIA GPU的并行计算能力。

cuBLAS库包含的函数涵盖了多种线性代数操作，如向量和矩阵加法、乘法、逆矩阵计算等，支持各种数据类型，包括单精度浮点数、双精度浮点数等。这些函数通常是BLAS（Basic Linear Algebra Subprograms）标准的实现，BLAS是一组标准的线性代数接口，被广泛用于各种数学、工程和科学计算中。

通过使用cuBLAS，开发者可以在不牺牲程序复杂度的情况下，为其应用程序提供高效的线性代数运算能力，这在深度学习、科学计算和工程模拟等领域尤其重要。例如，在深度学习中，矩阵乘法是训练神经网络的基本操作之一，利用cuBLAS执行这些操作可以显著加快训练过程。

简而言之，cuBLAS是为了在NVIDIA GPU上高效执行线性代数运算而设计的，它使得能够在支持CUDA的GPU上进行大规模数学计算成为可能。

在新的cublas4.0之后，使用了新的cuBlasAPI：`cublas_v2.h`


新版本的cuBLAS库通过引入`cublas_v2.h`头文件，提供了一系列改进和新特性，这些在旧版的cuBLAS API中是不存在的。下面是这些改进和新特性的概述及其对CUDA编程模式的影响：

1. 显式的库上下文句柄

- **改进**：在新的cuBLAS API中，库上下文的句柄通过`cublasCreate()`函数初始化，并且需要在之后的每个库函数调用中显式传递。这一改变允许用户在使用多个主机线程和多个GPU时，对库的设置有更多的控制权。同时，这也使得cuBLAS API能够重入（reentrant），即可以安全地在多个线程中调用。
- **影响**：这使得开发者能够在复杂的多线程和多GPU环境中更灵活、更有效地使用cuBLAS库，提高了程序的并行性和可控性。

2. 引用传递的标量参数

- **改进**：与旧版API相比，新API允许标量参数`\alpha`和`\beta`在主机或设备上通过引用传递，而不是仅在主机上通过值传递。这一改变允许库函数在使用流（streams）异步执行时，能够处理由之前的核函数生成的`\alpha`和`\beta`。
- **影响**：这一特性增强了程序的异步执行能力，使得在执行核函数链时能够实现更高的并行度。

3. 通过引用返回的标量结果

- **改进**：新API允许库例程返回的标量结果可以在主机或设备上通过引用返回，而不是仅在主机上通过值返回。这一改变允许库例程在标量结果由设备上的引用生成时，能够被异步调用，从而实现最大的并行性。
- **影响**：通过这种方式，开发者可以更高效地利用GPU资源，尤其是在需要处理复杂数据依赖关系的场景中。

4. 错误状态返回

- **改进**：所有的cuBLAS库函数调用都返回一个错误状态`cublasStatus_t`。这一改变便于调试并简化了软件开发过程。注意，`cublasStatus`被重命名为`cublasStatus_t`，以与cuBLAS库中的其他类型更一致。
- **影响**：这一机制使得开发者能够更容易地检测和处理函数调用中可能发生的错误，提高了代码的健壮性和可维护性。

5. 弃用的内存管理函数

- **改进**：`cublasAlloc()`和`cublasFree()`函数已被弃用。这一改变去除了这些不必要的包装器，分别围绕`cudaMalloc()`和`cudaFree()`。
- **影响**：这一改变简化了内存管理，直接使用CUDA的内存分配和释放函数，减少了API的冗余，使得代码更加直接和清晰。

6. 函数重命名

- **改进**：`cublasSetKernelStream()`函数被重命名为`cublasSetStream()`，以与其他CUDA库更一致。
- **影响**：这一改变提高了CUDA库之间的一致性，使得开发者在使用多个CUDA库时，能够更容易地记住和应用函数调用。

### 1.1 句柄handle

Handle机制在许多高性能计算库和框架中都是一种常见的设计模式，用于管理和维护资源的状态和上下文信息。在cuBLAS库中，handle的作用尤为重要，因为它允许开发者在使用库函数进行数学计算时，拥有更细粒度的控制能力。下面是handle机制的一些关键作用和好处：

1. 资源管理

- **上下文管理**：Handle作为一个上下文对象，存储了库函数操作所需的所有状态信息，包括配置设置、内存分配状态、设备信息等。这使得库能够在多个不同的操作之间保持状态的一致性。

2. **并发和多线程编程**

- **独立操作**：在多线程环境中，每个线程可以拥有自己的handle，使得每个线程的计算操作可以独立进行，互不干扰。这对于在多GPU环境下进行高效计算尤其重要。

3. **灵活性和可控性**

- **自定义配置**：通过不同的handle，用户可以对不同的计算任务设置不同的配置参数，如流（stream）优先级、计算精度等，从而根据具体需求优化性能。

4. **错误处理**

- **错误状态跟踪**：Handle还能够捕获和存储库函数调用过程中出现的错误状态，便于开发者进行错误检测和处理。

5. **重入性**

- **函数重入**：Handle机制使得cuBLAS库函数可以重入，即同一函数可以在不同的上下文（handle）中被多次调用，而不会导致状态混乱。这对于编写复杂的并行计算程序非常重要。

**示例**

在CUDA编程中，创建cuBLAS的handle通常是这样的：

```c++
cublasHandle_t handle;
cublasCreate(&handle);
```

之后，你可以使用这个handle来执行各种矩阵运算，如矩阵乘法：

```c++
cublasSgemm(handle, ...);
```

完成计算后，需要销毁handle来释放资源：

```c++
cublasDestroy(handle);
```





### 1.2 handle的具体作用（没有handle会怎么样）

首先需要理解，库有自己的状态

> 
> 库保持状态的原因根植于提供更高效、灵活且易于使用的编程模式的需求。状态管理允许库维护跨多个函数调用的信息，支持高级功能，优化性能，并为用户提供定制化服务。下面是一些具体原因和例子，解释为什么库会有状态：
>
> ### 1. **维护上下文信息**
>
> - **例子**：图形渲染库可能需要跟踪当前的绘图上下文，包括使用的颜色、线条粗细、字体设置等。这样，当绘制图形或文本时，就无需在每次调用时重新指定这些信息。
>
> ### 2. **性能优化**
>
> - **例子**：数值计算库（如cuBLAS）会预分配内存池来优化频繁的小量内存分配和释放操作。通过在库的状态中跟踪已分配的内存，可以显著减少内存管理的开销，提高计算性能。

没有handle机制的库或框架，其状态管理和资源分配通常会全局进行，这在多任务、多线程或要求高度并行处理的场景中会引起多种问题。下面通过对比的方式，说明没有handle和有handle机制的差别及各自的影响。

#### 没有Handle的情况

##### 全局状态管理

- **问题示例**：假设你在使用一个图形处理库，该库全局管理着图形渲染的状态（如颜色模式、渲染缓冲区等）。如果你在一个复杂的应用中，需要同时进行2D渲染和3D渲染，且它们需要不同的渲染状态。在这种没有handle机制的设计下，每次在进行2D和3D渲染切换时，都需要重新设置整个库的状态，这不仅效率低下，而且容易出错，因为一个任务的状态设置可能会不小心“覆盖”另一个任务的状态。

##### 并发和多线程编程的限制

- **问题示例**：在没有handle机制的并行计算库中，所有的线程共享相同的资源和状态配置。如果一个线程更改了库的配置（比如，调整了计算精度），这个更改会影响到其他所有线程的计算结果。这种设计使得并行编程复杂且容易出错，因为需要额外的同步机制来保证状态的一致性。

#### 有Handle的情况

##### 独立的状态管理

- **好处示例**：使用handle机制的图形处理库允许每个渲染任务有其独立的状态和资源。这样，即使应用中同时进行2D和3D渲染，每个渲染任务也可以通过自己的handle来维护各自的状态，互不干扰。这提高了效率和可靠性，因为状态的更改局限于特定的上下文中。

##### 并发和多线程编程的优势

- **好处示例**：在支持handle机制的并行计算库中，每个线程可以创建自己的handle实例。这意味着每个线程可以独立地配置和管理其计算资源，不会互相影响。例如，在使用cuBLAS进行矩阵运算时，不同的线程可以针对不同的GPU设备或CUDA流进行操作，每个操作通过各自的handle进行管理。这极大地提高了并发编程的效率和灵活性。