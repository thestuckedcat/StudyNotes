# 1. 并行计算

## 1.1 并行计算的概念

* 应用程序的潜在并行可能性指的是当系统资源是可用的情况下，可以通过任何顺序执行程序中的操作，而不会造成逻辑上的问题或是错误的结果。

* 并行硬件有许多不同的特性，我们着重介绍其中的几种非常规硬件：

  * **超线程**
    * 超线程的目的是提高每个CPU核心的效率，它通过在单个物理核心中模拟出两个逻辑核心来实现
    * ==超线程允许一个核心在一个时钟周期内处理两个线程==(超线程并不刻意同时执行两个线程，而是可以在这两个线程之间快速切换，也就是将两个指令队列交错的运行在硬件逻辑单元上)

  * **向量处理器**:
    * 向量处理器，也叫数组处理器，是专门用于执行向量计算的处理器，其不是对单个数据项进行标量操作，而是对数据向量的并行操作。
    * 向量处理器通常拥有==高带宽的内存访问能力==
    * 向量处理器的==位宽==(向量单位)指定了同时执行的指令数。例如一个256位宽的的向量单元可以同时执行4个64位(double)或是8个32位(float)的指令。
    * 向量处理器通常包含专门的硬件：向量寄存器，向量算术逻辑单元。
    * SIMD指令集是向量处理思想的一种实现。

  * **并行资源计算例子**：以一个具有超线程的16核CPU和一个256位宽的向量单元为例：
    * 考虑到每个核心可以执行两个线程(超线程),每个线程可以在单个指令中操作(256/64)个double数据
    * 16核$\times$2超线程$\times$(256位宽的向量单元)/64位(double) = 128路并行
    * 因此一个使用单核且没有向量化的串行程序只使用了该处理器0.8%的理论处理性能。

* 计算应用程序的能耗：

  * $P = N(个处理器)\times(R瓦/处理器)\times (T小时)$
  * 其中P为能耗，N为处理器数量，R为热设计功率，T为应用程序运行时间



## 1.2 并行计算的基本定律

相比与串行计算中，所有的操作都与时钟频率线性相关，在并行计算中，要复杂得多。

### 1.2.1 Amdahl定律

代码中并不只有并行代码，串行代码对并行结果的同步需求也是不可避免的。该定律根据并行代码数量，描述了计算的潜在加速比。
$$
Speedup(N)=\frac{1}{S + \frac{P}{N}}
$$
P是代码并行部分的分数，S是代码串行部分的分数，这意味着$P+S=1$，$N$是处理器数量。

Amdahl定律强调，无论让代码并行部分运行有多快，总会受到代码运行串行部分的限制，在固定规模的问题中这种标度称为==强标度==

例如，如果程序的95%可以并行化，剩下的5%必须串行执行，那么即使你增加无限多的处理器，根据Amdahl定律，你也只能实现20倍的加速（假设并行部分是完美的并行）。

### 1.2.2 Gustafson-Barsis

$$
Speedup(N) = N-S(N-1)
$$

N是处理器数量，S是串行部分分数。

这一定律提供了一个更乐观的视角，强调了随着处理器数量的增加，我们可以在相同的时间内处理更多的数据，而不仅仅是加速已有的固定大小的问题。

Gustafson-Barsis定律的主要观点是：随着处理器数量的增加，我们通常会增加问题的大小，因此并行部分的绝对时间会增加，而串行部分的绝对时间保持不变。

简而言之，Gustafson-Barsis定律提供了一个更实际、更乐观的并行计算视角，强调了随着处理器数量的增加，我们可以处理更大的数据集或问题规模。

也就是弱标度：==弱标度定义为对于每个处理器的固定问题规模，求解时间如何随处理器数量而变化==